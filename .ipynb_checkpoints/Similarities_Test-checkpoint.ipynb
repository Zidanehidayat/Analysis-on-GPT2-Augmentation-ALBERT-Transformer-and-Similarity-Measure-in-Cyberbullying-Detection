{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d9e60dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from math import sqrt, pow, exp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "501f6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_COLUMN = 1\n",
    "LABEL_COLUMN = 0\n",
    "df_ORI = pd.read_csv(\"data/data_training_90.txt\", sep=\"\\t\", header=None)\n",
    "df_ORI.columns = [LABEL_COLUMN, DATA_COLUMN]\n",
    "df_AUG = pd.read_csv(\"data/data_training_90_1_d_NO_RS(augonly).txt\", sep=\"\\t\", header=None)\n",
    "df_AUG.columns = [LABEL_COLUMN, DATA_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "508927e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_model_name = \"distiluse-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b295981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(x,y):\n",
    "    \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "def squared_sum(x):\n",
    "    \"\"\" return 3 rounded square rooted value \"\"\"\n",
    "    \n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    " \n",
    "def euclidean_distance(x,y):\n",
    "    \"\"\" return euclidean distance between two lists \"\"\"\n",
    "    \n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    "\n",
    "def distance_to_similarity(distance):\n",
    "    return 1/exp(distance)\n",
    "\n",
    "def cos_similarity(x,y):\n",
    "    \"\"\" return cosine similarity between two lists \"\"\"    \n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = squared_sum(x)*squared_sum(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "\n",
    "def create_embeddings (text, SentenceTransformer_model): \n",
    "    embeddings = SentenceTransformer_model.encode(text)\n",
    "    if len(embeddings) !=0:\n",
    "        return list(embeddings)\n",
    "    else:\n",
    "        return [0]\n",
    "def calculate_bleu_scores(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculates BLEU 1-4 scores based on NLTK functionality\n",
    "\n",
    "    Args:\n",
    "        references: List of reference sentences\n",
    "        hypotheses: List of generated sentences\n",
    "\n",
    "    Returns:\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4: BLEU scores\n",
    "\n",
    "    \"\"\"\n",
    "    #return len(references), len(hypotheses)\n",
    "    bleu_1 = np.round(corpus_bleu(references, hypotheses, weights=(1.0, 0., 0., 0.)), decimals=2)\n",
    "    bleu_2 = np.round(corpus_bleu(references, hypotheses, weights=(0.50, 0.50, 0., 0.)), decimals=2)\n",
    "    bleu_3 = np.round(corpus_bleu(references, hypotheses, weights=(0.34, 0.33, 0.33, 0.)), decimals=2)\n",
    "    bleu_4 = np.round(corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25)), decimals=2)\n",
    "    return bleu_1, bleu_2, bleu_3, bleu_4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fbe4a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Counter: 1\n",
      "Rows Counter: 2\n",
      "Rows Counter: 3\n",
      "Rows Counter: 4\n",
      "Rows Counter: 5\n",
      "Rows Counter: 6\n",
      "Rows Counter: 7\n",
      "Rows Counter: 8\n",
      "Rows Counter: 9\n",
      "Rows Counter: 10\n",
      "Rows Counter: 11\n",
      "Rows Counter: 12\n",
      "Rows Counter: 13\n",
      "Rows Counter: 14\n",
      "Rows Counter: 15\n",
      "Rows Counter: 16\n",
      "Rows Counter: 17\n",
      "Rows Counter: 18\n",
      "Rows Counter: 19\n",
      "Rows Counter: 20\n",
      "Rows Counter: 21\n",
      "Rows Counter: 22\n",
      "Rows Counter: 23\n",
      "Rows Counter: 24\n",
      "Rows Counter: 25\n",
      "Rows Counter: 26\n",
      "Rows Counter: 27\n",
      "Rows Counter: 28\n",
      "Rows Counter: 29\n",
      "Rows Counter: 30\n",
      "Rows Counter: 31\n",
      "Rows Counter: 32\n",
      "Rows Counter: 33\n",
      "Rows Counter: 34\n",
      "Rows Counter: 35\n",
      "Rows Counter: 36\n",
      "Rows Counter: 37\n",
      "Rows Counter: 38\n",
      "Rows Counter: 39\n",
      "Rows Counter: 40\n",
      "Rows Counter: 41\n",
      "Rows Counter: 42\n",
      "Rows Counter: 43\n",
      "Rows Counter: 44\n",
      "Rows Counter: 45\n",
      "Rows Counter: 46\n",
      "Rows Counter: 47\n",
      "Rows Counter: 48\n",
      "Rows Counter: 49\n",
      "Rows Counter: 50\n",
      "Rows Counter: 51\n",
      "Rows Counter: 52\n",
      "Rows Counter: 53\n",
      "Rows Counter: 54\n",
      "Rows Counter: 55\n",
      "Rows Counter: 56\n",
      "Rows Counter: 57\n",
      "Rows Counter: 58\n",
      "Rows Counter: 59\n",
      "Rows Counter: 60\n",
      "Rows Counter: 61\n",
      "Rows Counter: 62\n",
      "Rows Counter: 63\n",
      "Rows Counter: 64\n",
      "Rows Counter: 65\n",
      "Rows Counter: 66\n",
      "Rows Counter: 67\n",
      "Rows Counter: 68\n",
      "Rows Counter: 69\n",
      "Rows Counter: 70\n",
      "Rows Counter: 71\n",
      "Rows Counter: 72\n",
      "Rows Counter: 73\n",
      "Rows Counter: 74\n",
      "Rows Counter: 75\n",
      "Rows Counter: 76\n",
      "Rows Counter: 77\n",
      "Rows Counter: 78\n",
      "Rows Counter: 79\n",
      "Rows Counter: 80\n",
      "Rows Counter: 81\n",
      "Rows Counter: 82\n",
      "Rows Counter: 83\n",
      "Rows Counter: 84\n",
      "Rows Counter: 85\n",
      "Rows Counter: 86\n",
      "Rows Counter: 87\n",
      "Rows Counter: 88\n",
      "Rows Counter: 89\n",
      "Rows Counter: 90\n",
      "Rows Counter: 91\n",
      "Rows Counter: 92\n",
      "Rows Counter: 93\n",
      "Rows Counter: 94\n",
      "Rows Counter: 95\n",
      "Rows Counter: 96\n",
      "Rows Counter: 97\n",
      "Rows Counter: 98\n",
      "Rows Counter: 99\n",
      "Rows Counter: 100\n",
      "Rows Counter: 101\n",
      "Rows Counter: 102\n",
      "Rows Counter: 103\n",
      "Rows Counter: 104\n",
      "Rows Counter: 105\n",
      "Rows Counter: 106\n",
      "Rows Counter: 107\n",
      "Rows Counter: 108\n",
      "Rows Counter: 109\n",
      "Rows Counter: 110\n",
      "Rows Counter: 111\n",
      "Rows Counter: 112\n",
      "Rows Counter: 113\n",
      "Rows Counter: 114\n",
      "Rows Counter: 115\n",
      "Rows Counter: 116\n",
      "Rows Counter: 117\n",
      "Rows Counter: 118\n",
      "Rows Counter: 119\n",
      "Rows Counter: 120\n",
      "Rows Counter: 121\n",
      "Rows Counter: 122\n",
      "Rows Counter: 123\n",
      "Rows Counter: 124\n",
      "Rows Counter: 125\n",
      "Rows Counter: 126\n",
      "Rows Counter: 127\n",
      "Rows Counter: 128\n",
      "Rows Counter: 129\n",
      "Rows Counter: 130\n",
      "Rows Counter: 131\n",
      "Rows Counter: 132\n",
      "Rows Counter: 133\n",
      "Rows Counter: 134\n",
      "Rows Counter: 135\n",
      "Rows Counter: 136\n",
      "Rows Counter: 137\n",
      "Rows Counter: 138\n",
      "Rows Counter: 139\n",
      "Rows Counter: 140\n",
      "Rows Counter: 141\n",
      "Rows Counter: 142\n",
      "Rows Counter: 143\n",
      "Rows Counter: 144\n",
      "Rows Counter: 145\n",
      "Rows Counter: 146\n",
      "Rows Counter: 147\n",
      "Rows Counter: 148\n",
      "Rows Counter: 149\n",
      "Rows Counter: 150\n",
      "Rows Counter: 151\n",
      "Rows Counter: 152\n",
      "Rows Counter: 153\n",
      "Rows Counter: 154\n",
      "Rows Counter: 155\n",
      "Rows Counter: 156\n",
      "Rows Counter: 157\n",
      "Rows Counter: 158\n",
      "Rows Counter: 159\n",
      "Rows Counter: 160\n",
      "Rows Counter: 161\n",
      "Rows Counter: 162\n",
      "Rows Counter: 163\n",
      "Rows Counter: 164\n",
      "Rows Counter: 165\n",
      "Rows Counter: 166\n",
      "Rows Counter: 167\n",
      "Rows Counter: 168\n",
      "Rows Counter: 169\n",
      "Rows Counter: 170\n",
      "Rows Counter: 171\n",
      "Rows Counter: 172\n",
      "Rows Counter: 173\n",
      "Rows Counter: 174\n",
      "Rows Counter: 175\n",
      "Rows Counter: 176\n",
      "Rows Counter: 177\n",
      "Rows Counter: 178\n",
      "Rows Counter: 179\n",
      "Rows Counter: 180\n",
      "Rows Counter: 181\n",
      "Rows Counter: 182\n",
      "Rows Counter: 183\n",
      "Rows Counter: 184\n",
      "Rows Counter: 185\n",
      "Rows Counter: 186\n",
      "Rows Counter: 187\n",
      "Rows Counter: 188\n",
      "Rows Counter: 189\n",
      "Rows Counter: 190\n",
      "Rows Counter: 191\n",
      "Rows Counter: 192\n",
      "Rows Counter: 193\n",
      "Rows Counter: 194\n",
      "Rows Counter: 195\n",
      "Rows Counter: 196\n",
      "Rows Counter: 197\n",
      "Rows Counter: 198\n",
      "Rows Counter: 199\n",
      "Rows Counter: 200\n",
      "Rows Counter: 201\n",
      "Rows Counter: 202\n",
      "Rows Counter: 203\n",
      "Rows Counter: 204\n",
      "Rows Counter: 205\n",
      "Rows Counter: 206\n",
      "Rows Counter: 207\n",
      "Rows Counter: 208\n",
      "Rows Counter: 209\n",
      "Rows Counter: 210\n",
      "Rows Counter: 211\n",
      "Rows Counter: 212\n",
      "Rows Counter: 213\n",
      "Rows Counter: 214\n",
      "Rows Counter: 215\n",
      "Rows Counter: 216\n",
      "Rows Counter: 217\n",
      "Rows Counter: 218\n",
      "Rows Counter: 219\n",
      "Rows Counter: 220\n",
      "Rows Counter: 221\n",
      "Rows Counter: 222\n",
      "Rows Counter: 223\n",
      "Rows Counter: 224\n",
      "Rows Counter: 225\n",
      "Rows Counter: 226\n",
      "Rows Counter: 227\n",
      "Rows Counter: 228\n",
      "Rows Counter: 229\n",
      "Rows Counter: 230\n",
      "Rows Counter: 231\n",
      "Rows Counter: 232\n",
      "Rows Counter: 233\n",
      "Rows Counter: 234\n",
      "Rows Counter: 235\n",
      "Rows Counter: 236\n",
      "Rows Counter: 237\n",
      "Rows Counter: 238\n",
      "Rows Counter: 239\n",
      "Rows Counter: 240\n",
      "Rows Counter: 241\n",
      "Rows Counter: 242\n",
      "Rows Counter: 243\n",
      "Rows Counter: 244\n",
      "Rows Counter: 245\n",
      "Rows Counter: 246\n",
      "Rows Counter: 247\n",
      "Rows Counter: 248\n",
      "Rows Counter: 249\n",
      "Rows Counter: 250\n",
      "Rows Counter: 251\n",
      "Rows Counter: 252\n",
      "Rows Counter: 253\n",
      "Rows Counter: 254\n",
      "Rows Counter: 255\n",
      "Rows Counter: 256\n",
      "Rows Counter: 257\n",
      "Rows Counter: 258\n",
      "Rows Counter: 259\n",
      "Rows Counter: 260\n",
      "Rows Counter: 261\n",
      "Rows Counter: 262\n",
      "Rows Counter: 263\n",
      "Rows Counter: 264\n",
      "Rows Counter: 265\n",
      "Rows Counter: 266\n",
      "Rows Counter: 267\n",
      "Rows Counter: 268\n",
      "Rows Counter: 269\n",
      "Rows Counter: 270\n",
      "Rows Counter: 271\n",
      "Rows Counter: 272\n",
      "Rows Counter: 273\n",
      "Rows Counter: 274\n",
      "Rows Counter: 275\n",
      "Rows Counter: 276\n",
      "Rows Counter: 277\n",
      "Rows Counter: 278\n",
      "Rows Counter: 279\n",
      "Rows Counter: 280\n",
      "Rows Counter: 281\n",
      "Rows Counter: 282\n",
      "Rows Counter: 283\n",
      "Rows Counter: 284\n",
      "Rows Counter: 285\n",
      "Rows Counter: 286\n",
      "Rows Counter: 287\n",
      "Rows Counter: 288\n",
      "Rows Counter: 289\n",
      "Rows Counter: 290\n",
      "Rows Counter: 291\n",
      "Rows Counter: 292\n",
      "Rows Counter: 293\n",
      "Rows Counter: 294\n",
      "Rows Counter: 295\n",
      "Rows Counter: 296\n",
      "Rows Counter: 297\n",
      "Rows Counter: 298\n",
      "Rows Counter: 299\n",
      "Rows Counter: 300\n",
      "Rows Counter: 301\n",
      "Rows Counter: 302\n",
      "Rows Counter: 303\n",
      "Rows Counter: 304\n",
      "Rows Counter: 305\n",
      "Rows Counter: 306\n",
      "Rows Counter: 307\n",
      "Rows Counter: 308\n",
      "Rows Counter: 309\n",
      "Rows Counter: 310\n",
      "Rows Counter: 311\n",
      "Rows Counter: 312\n",
      "Rows Counter: 313\n",
      "Rows Counter: 314\n",
      "Rows Counter: 315\n",
      "Rows Counter: 316\n",
      "Rows Counter: 317\n",
      "Rows Counter: 318\n",
      "Rows Counter: 319\n",
      "Rows Counter: 320\n",
      "Rows Counter: 321\n",
      "Rows Counter: 322\n",
      "Rows Counter: 323\n",
      "Rows Counter: 324\n",
      "Rows Counter: 325\n",
      "Rows Counter: 326\n",
      "Rows Counter: 327\n",
      "Rows Counter: 328\n",
      "Rows Counter: 329\n",
      "Rows Counter: 330\n",
      "Rows Counter: 331\n",
      "Rows Counter: 332\n",
      "Rows Counter: 333\n",
      "Rows Counter: 334\n",
      "Rows Counter: 335\n",
      "Rows Counter: 336\n",
      "Rows Counter: 337\n",
      "Rows Counter: 338\n",
      "Rows Counter: 339\n",
      "Rows Counter: 340\n",
      "Rows Counter: 341\n",
      "Rows Counter: 342\n",
      "Rows Counter: 343\n",
      "Rows Counter: 344\n",
      "Rows Counter: 345\n",
      "Rows Counter: 346\n",
      "Rows Counter: 347\n",
      "Rows Counter: 348\n",
      "Rows Counter: 349\n",
      "Rows Counter: 350\n",
      "Rows Counter: 351\n",
      "Rows Counter: 352\n",
      "Rows Counter: 353\n",
      "Rows Counter: 354\n",
      "Rows Counter: 355\n",
      "Rows Counter: 356\n",
      "Rows Counter: 357\n",
      "Rows Counter: 358\n",
      "Rows Counter: 359\n",
      "Rows Counter: 360\n"
     ]
    }
   ],
   "source": [
    "SentenceTransformer_model = SentenceTransformer(cos_model_name)\n",
    "df           = pd.DataFrame()\n",
    "newDF        = pd.DataFrame()\n",
    "df           = df_ORI\n",
    "#df.reset_index(inplace=True)\n",
    "cntr         = 1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print('Rows Counter: ' + str(cntr))\n",
    "    text     = row[DATA_COLUMN]\n",
    "    all_text = df_AUG.iloc[index][DATA_COLUMN]\n",
    "    embd1 = create_embeddings(text=text, SentenceTransformer_model=SentenceTransformer_model)\n",
    "    embd2 = create_embeddings(text=all_text, SentenceTransformer_model=SentenceTransformer_model)\n",
    "    new_embd1 = ','.join(str(x) for x in embd1)\n",
    "    new_embd2 = ','.join(str(x) for x in embd2)\n",
    "    esim = euclidean_distance(embd1, embd2)\n",
    "    csim = cos_similarity(embd1, embd2)\n",
    "    jsim = jaccard_similarity(text, all_text)    \n",
    "    tmp = { \n",
    "        'text': [row[DATA_COLUMN]], \n",
    "        'label': [row[LABEL_COLUMN]], \n",
    "        'all_text': [all_text], \n",
    "        'original_embedding': [new_embd1], \n",
    "        'new_embedding': [new_embd2], \n",
    "        'ecu_similarity': [esim], \n",
    "        'cos_similarity': [csim], \n",
    "        'jacc_similarity': [jsim] \n",
    "    }\n",
    "    tmpDF = pd.DataFrame(tmp)\n",
    "#     print(tmpDF)\n",
    "    newDF = pd.concat([newDF, tmpDF], ignore_index=True)\n",
    "    \n",
    "    cntr = cntr + 1\n",
    "    #if cntr == 10:\n",
    "#     #    break;\n",
    "        \n",
    "#     # GPU Monitor\n",
    "#     if index%10 == 0:\n",
    "#         GPUs = GPU.getGPUs()  \n",
    "#         gpu = GPUs[0]    \n",
    "#         print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))        \n",
    "#         torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "396acd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03885621  0.01854846 -0.04066142 ...  0.01009197 -0.01660532\n",
      "  -0.00138948]\n",
      " [-0.00059496 -0.00924198 -0.05870509 ...  0.0163878   0.0150957\n",
      "  -0.04368323]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "acb11756",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF['text_split'] = [list(x.split()) for x in newDF['text']]\n",
    "newDF['all_text_split'] = [x.split() for x in newDF['all_text']]\n",
    "# df['new_text_split'] = [str(x).split() for x in df['new_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51c38163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "newDF[['bleu_sim_1','bleu_sim_2','bleu_sim_3','bleu_sim_4']] = [ calculate_bleu_scores ([[x]],[y]) for x, y in zip(newDF['text_split'], newDF['all_text_split'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ab7e3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>all_text</th>\n",
       "      <th>original_embedding</th>\n",
       "      <th>new_embedding</th>\n",
       "      <th>ecu_similarity</th>\n",
       "      <th>cos_similarity</th>\n",
       "      <th>jacc_similarity</th>\n",
       "      <th>text_split</th>\n",
       "      <th>all_text_split</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_2</th>\n",
       "      <th>bleu_sim_3</th>\n",
       "      <th>bleu_sim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lucu kak abbey cantik kayak orang haru</td>\n",
       "      <td>1</td>\n",
       "      <td>lucu kak abbey cantik adiwarna kayak orang adi...</td>\n",
       "      <td>-0.008952069,0.040075563,0.009347845,-0.011252...</td>\n",
       "      <td>-0.0136766415,0.041937623,0.0019431965,-0.0123...</td>\n",
       "      <td>0.164420</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[lucu, kak, abbey, cantik, kayak, orang, haru]</td>\n",
       "      <td>[lucu, kak, abbey, cantik, adiwarna, kayak, or...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heran deh ngatain baperan wajar dese baper udi...</td>\n",
       "      <td>0</td>\n",
       "      <td>terpesona deh ngatain baperan wajar dese baper...</td>\n",
       "      <td>-0.0025755772,0.02613186,0.007338423,-0.015779...</td>\n",
       "      <td>-0.0056755748,0.031803522,6.8956055e-05,-0.015...</td>\n",
       "      <td>0.259165</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>[heran, deh, ngatain, baperan, wajar, dese, ba...</td>\n",
       "      <td>[terpesona, deh, ngatain, baperan, wajar, dese...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jujur ni org bagus kaga oplasada tu foto sblm ...</td>\n",
       "      <td>0</td>\n",
       "      <td>jujur ni org elok kaga oplasada tu potret sblm...</td>\n",
       "      <td>-0.035448533,-0.002518586,0.0033979444,-0.0242...</td>\n",
       "      <td>-0.026780076,0.0033431114,0.036886457,-0.01977...</td>\n",
       "      <td>0.321123</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>[jujur, ni, org, bagus, kaga, oplasada, tu, fo...</td>\n",
       "      <td>[jujur, ni, org, elok, kaga, oplasada, tu, pot...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haduuh orang gak akhlak bangeg kerja antem mul...</td>\n",
       "      <td>0</td>\n",
       "      <td>adab haduuh orang adab gak akhlak bangeg kerja...</td>\n",
       "      <td>0.0004594625,0.0074383444,0.011340768,-0.00337...</td>\n",
       "      <td>-0.00016716315,0.003545129,0.0072791334,-0.003...</td>\n",
       "      <td>0.137265</td>\n",
       "      <td>0.945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[haduuh, orang, gak, akhlak, bangeg, kerja, an...</td>\n",
       "      <td>[adab, haduuh, orang, adab, gak, akhlak, bange...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bingung jujur media rebut ngeliput orang kayak...</td>\n",
       "      <td>0</td>\n",
       "      <td>waras jujur media kayak ngeliput orang rebut c...</td>\n",
       "      <td>-0.030819891,0.03667834,-0.022147859,-0.026122...</td>\n",
       "      <td>-0.028461238,0.024706094,-0.03251241,-0.031904...</td>\n",
       "      <td>0.193797</td>\n",
       "      <td>0.967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[bingung, jujur, media, rebut, ngeliput, orang...</td>\n",
       "      <td>[waras, jujur, media, kayak, ngeliput, orang, ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0             lucu kak abbey cantik kayak orang haru      1   \n",
       "1  heran deh ngatain baperan wajar dese baper udi...      0   \n",
       "2  jujur ni org bagus kaga oplasada tu foto sblm ...      0   \n",
       "3  haduuh orang gak akhlak bangeg kerja antem mul...      0   \n",
       "4  bingung jujur media rebut ngeliput orang kayak...      0   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  lucu kak abbey cantik adiwarna kayak orang adi...   \n",
       "1  terpesona deh ngatain baperan wajar dese baper...   \n",
       "2  jujur ni org elok kaga oplasada tu potret sblm...   \n",
       "3  adab haduuh orang adab gak akhlak bangeg kerja...   \n",
       "4  waras jujur media kayak ngeliput orang rebut c...   \n",
       "\n",
       "                                  original_embedding  \\\n",
       "0  -0.008952069,0.040075563,0.009347845,-0.011252...   \n",
       "1  -0.0025755772,0.02613186,0.007338423,-0.015779...   \n",
       "2  -0.035448533,-0.002518586,0.0033979444,-0.0242...   \n",
       "3  0.0004594625,0.0074383444,0.011340768,-0.00337...   \n",
       "4  -0.030819891,0.03667834,-0.022147859,-0.026122...   \n",
       "\n",
       "                                       new_embedding  ecu_similarity  \\\n",
       "0  -0.0136766415,0.041937623,0.0019431965,-0.0123...        0.164420   \n",
       "1  -0.0056755748,0.031803522,6.8956055e-05,-0.015...        0.259165   \n",
       "2  -0.026780076,0.0033431114,0.036886457,-0.01977...        0.321123   \n",
       "3  -0.00016716315,0.003545129,0.0072791334,-0.003...        0.137265   \n",
       "4  -0.028461238,0.024706094,-0.03251241,-0.031904...        0.193797   \n",
       "\n",
       "   cos_similarity  jacc_similarity  \\\n",
       "0           0.951         0.888889   \n",
       "1           0.880         0.958333   \n",
       "2           0.762         0.952381   \n",
       "3           0.945         1.000000   \n",
       "4           0.967         1.000000   \n",
       "\n",
       "                                          text_split  \\\n",
       "0     [lucu, kak, abbey, cantik, kayak, orang, haru]   \n",
       "1  [heran, deh, ngatain, baperan, wajar, dese, ba...   \n",
       "2  [jujur, ni, org, bagus, kaga, oplasada, tu, fo...   \n",
       "3  [haduuh, orang, gak, akhlak, bangeg, kerja, an...   \n",
       "4  [bingung, jujur, media, rebut, ngeliput, orang...   \n",
       "\n",
       "                                      all_text_split  bleu_sim_1  bleu_sim_2  \\\n",
       "0  [lucu, kak, abbey, cantik, adiwarna, kayak, or...        0.78        0.62   \n",
       "1  [terpesona, deh, ngatain, baperan, wajar, dese...        0.68        0.56   \n",
       "2  [jujur, ni, org, elok, kaga, oplasada, tu, pot...        0.73        0.56   \n",
       "3  [adab, haduuh, orang, adab, gak, akhlak, bange...        0.82        0.76   \n",
       "4  [waras, jujur, media, kayak, ngeliput, orang, ...        1.00        0.52   \n",
       "\n",
       "   bleu_sim_3  bleu_sim_4  \n",
       "0        0.48        0.37  \n",
       "1        0.48        0.39  \n",
       "2        0.42        0.00  \n",
       "3        0.68        0.63  \n",
       "4        0.00        0.00  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8396d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.to_csv(\"data/similarity_data_training_90_1_d_NO_RS.txt\", sep=\"\\t\", header=0,encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "118e2aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECU': 0.2458361729956375,\n",
       " 'COS': 0.8945,\n",
       " 'JAC': 0.9385908119551419,\n",
       " 'BLEU': 0.8154722222222224}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIM_COFFICIENTS_THRESHOLDS = {'ECU': newDF[\"ecu_similarity\"].mean(), 'COS':newDF[\"cos_similarity\"].mean(), 'JAC':newDF[\"jacc_similarity\"].mean(), 'BLEU':newDF[\"bleu_sim_1\"].mean()}\n",
    "SIM_COFFICIENTS_THRESHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0116c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
