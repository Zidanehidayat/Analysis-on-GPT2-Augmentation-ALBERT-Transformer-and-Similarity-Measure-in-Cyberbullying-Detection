{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1f4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e60dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# util\n",
    "from math import sqrt, pow, exp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501f6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_COLUMN = 1\n",
    "LABEL_COLUMN = 0\n",
    "df_ORI = pd.read_csv(\"data/data_training_90.txt\", sep=\"\\t\", header=None)#, encoding=\"UTF-16\")\n",
    "df_ORI.columns = [LABEL_COLUMN, DATA_COLUMN]\n",
    "df_AUG = pd.read_csv(\"data/data_training_90_1_a_NO_RS(augonly).txt\", sep=\"\\t\", header=None)\n",
    "df_AUG.columns = [LABEL_COLUMN, DATA_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "508927e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_model_name = \"distiluse-base-multilingual-cased-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b295981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(x,y):\n",
    "    \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "def squared_sum(x):\n",
    "    \"\"\" return 3 rounded square rooted value \"\"\"\n",
    "    \n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    " \n",
    "def euclidean_distance(x,y):\n",
    "    \"\"\" return euclidean distance between two lists \"\"\"\n",
    "    \n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    "\n",
    "def distance_to_similarity(distance):\n",
    "    return 1/exp(distance)\n",
    "\n",
    "def cos_similarity(x,y):\n",
    "    \"\"\" return cosine similarity between two lists \"\"\"    \n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = squared_sum(x)*squared_sum(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "\n",
    "def create_embeddings (text, SentenceTransformer_model): \n",
    "    embeddings = SentenceTransformer_model.encode(text)\n",
    "    if len(embeddings) !=0:\n",
    "        return list(embeddings)\n",
    "    else:\n",
    "        return [0]\n",
    "def calculate_bleu_scores(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculates BLEU 1-4 scores based on NLTK functionality\n",
    "\n",
    "    Args:\n",
    "        references: List of reference sentences\n",
    "        hypotheses: List of generated sentences\n",
    "\n",
    "    Returns:\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4: BLEU scores\n",
    "\n",
    "    \"\"\"\n",
    "    #return len(references), len(hypotheses)\n",
    "    bleu_1 = np.round(corpus_bleu(references, hypotheses, weights=(1.0, 0., 0., 0.)), decimals=2)\n",
    "    bleu_2 = np.round(corpus_bleu(references, hypotheses, weights=(0.50, 0.50, 0., 0.)), decimals=2)\n",
    "    bleu_3 = np.round(corpus_bleu(references, hypotheses, weights=(0.34, 0.33, 0.33, 0.)), decimals=2)\n",
    "    bleu_4 = np.round(corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25)), decimals=2)\n",
    "    return bleu_1, bleu_2, bleu_3, bleu_4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe4a721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596b175cdf5a42c6ab14597eb64d9d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Server\\.cache\\huggingface\\hub\\models--sentence-transformers--distiluse-base-multilingual-cased-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf61d15c75d4f5f88b5a23afb74882b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549f5852eee841409f146e7cb228b17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9df815f43f44bb0bc7232ef2a671630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550c8759dc8b486e8950b961daf89739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d75bcea57d4e849959fa79de18997d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a868c6aef679452eb3f954373c5cd63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bfd146aca9453489c8ede258a99b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9c597111c342479937d84211de2736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows Counter: 1\n",
      "Rows Counter: 2\n",
      "Rows Counter: 3\n",
      "Rows Counter: 4\n",
      "Rows Counter: 5\n",
      "Rows Counter: 6\n",
      "Rows Counter: 7\n",
      "Rows Counter: 8\n",
      "Rows Counter: 9\n",
      "Rows Counter: 10\n",
      "Rows Counter: 11\n",
      "Rows Counter: 12\n",
      "Rows Counter: 13\n",
      "Rows Counter: 14\n",
      "Rows Counter: 15\n",
      "Rows Counter: 16\n",
      "Rows Counter: 17\n",
      "Rows Counter: 18\n",
      "Rows Counter: 19\n",
      "Rows Counter: 20\n",
      "Rows Counter: 21\n",
      "Rows Counter: 22\n",
      "Rows Counter: 23\n",
      "Rows Counter: 24\n",
      "Rows Counter: 25\n",
      "Rows Counter: 26\n",
      "Rows Counter: 27\n",
      "Rows Counter: 28\n",
      "Rows Counter: 29\n",
      "Rows Counter: 30\n",
      "Rows Counter: 31\n",
      "Rows Counter: 32\n",
      "Rows Counter: 33\n",
      "Rows Counter: 34\n",
      "Rows Counter: 35\n",
      "Rows Counter: 36\n",
      "Rows Counter: 37\n",
      "Rows Counter: 38\n",
      "Rows Counter: 39\n",
      "Rows Counter: 40\n",
      "Rows Counter: 41\n",
      "Rows Counter: 42\n",
      "Rows Counter: 43\n",
      "Rows Counter: 44\n",
      "Rows Counter: 45\n",
      "Rows Counter: 46\n",
      "Rows Counter: 47\n",
      "Rows Counter: 48\n",
      "Rows Counter: 49\n",
      "Rows Counter: 50\n",
      "Rows Counter: 51\n",
      "Rows Counter: 52\n",
      "Rows Counter: 53\n",
      "Rows Counter: 54\n",
      "Rows Counter: 55\n",
      "Rows Counter: 56\n",
      "Rows Counter: 57\n",
      "Rows Counter: 58\n",
      "Rows Counter: 59\n",
      "Rows Counter: 60\n",
      "Rows Counter: 61\n",
      "Rows Counter: 62\n",
      "Rows Counter: 63\n",
      "Rows Counter: 64\n",
      "Rows Counter: 65\n",
      "Rows Counter: 66\n",
      "Rows Counter: 67\n",
      "Rows Counter: 68\n",
      "Rows Counter: 69\n",
      "Rows Counter: 70\n",
      "Rows Counter: 71\n",
      "Rows Counter: 72\n",
      "Rows Counter: 73\n",
      "Rows Counter: 74\n",
      "Rows Counter: 75\n",
      "Rows Counter: 76\n",
      "Rows Counter: 77\n",
      "Rows Counter: 78\n",
      "Rows Counter: 79\n",
      "Rows Counter: 80\n",
      "Rows Counter: 81\n",
      "Rows Counter: 82\n",
      "Rows Counter: 83\n",
      "Rows Counter: 84\n",
      "Rows Counter: 85\n",
      "Rows Counter: 86\n",
      "Rows Counter: 87\n",
      "Rows Counter: 88\n",
      "Rows Counter: 89\n",
      "Rows Counter: 90\n",
      "Rows Counter: 91\n",
      "Rows Counter: 92\n",
      "Rows Counter: 93\n",
      "Rows Counter: 94\n",
      "Rows Counter: 95\n",
      "Rows Counter: 96\n",
      "Rows Counter: 97\n",
      "Rows Counter: 98\n",
      "Rows Counter: 99\n",
      "Rows Counter: 100\n",
      "Rows Counter: 101\n",
      "Rows Counter: 102\n",
      "Rows Counter: 103\n",
      "Rows Counter: 104\n",
      "Rows Counter: 105\n",
      "Rows Counter: 106\n",
      "Rows Counter: 107\n",
      "Rows Counter: 108\n",
      "Rows Counter: 109\n",
      "Rows Counter: 110\n",
      "Rows Counter: 111\n",
      "Rows Counter: 112\n",
      "Rows Counter: 113\n",
      "Rows Counter: 114\n",
      "Rows Counter: 115\n",
      "Rows Counter: 116\n",
      "Rows Counter: 117\n",
      "Rows Counter: 118\n",
      "Rows Counter: 119\n",
      "Rows Counter: 120\n",
      "Rows Counter: 121\n",
      "Rows Counter: 122\n",
      "Rows Counter: 123\n",
      "Rows Counter: 124\n",
      "Rows Counter: 125\n",
      "Rows Counter: 126\n",
      "Rows Counter: 127\n",
      "Rows Counter: 128\n",
      "Rows Counter: 129\n",
      "Rows Counter: 130\n",
      "Rows Counter: 131\n",
      "Rows Counter: 132\n",
      "Rows Counter: 133\n",
      "Rows Counter: 134\n",
      "Rows Counter: 135\n",
      "Rows Counter: 136\n",
      "Rows Counter: 137\n",
      "Rows Counter: 138\n",
      "Rows Counter: 139\n",
      "Rows Counter: 140\n",
      "Rows Counter: 141\n",
      "Rows Counter: 142\n",
      "Rows Counter: 143\n",
      "Rows Counter: 144\n",
      "Rows Counter: 145\n",
      "Rows Counter: 146\n",
      "Rows Counter: 147\n",
      "Rows Counter: 148\n",
      "Rows Counter: 149\n",
      "Rows Counter: 150\n",
      "Rows Counter: 151\n",
      "Rows Counter: 152\n",
      "Rows Counter: 153\n",
      "Rows Counter: 154\n",
      "Rows Counter: 155\n",
      "Rows Counter: 156\n",
      "Rows Counter: 157\n",
      "Rows Counter: 158\n",
      "Rows Counter: 159\n",
      "Rows Counter: 160\n",
      "Rows Counter: 161\n",
      "Rows Counter: 162\n",
      "Rows Counter: 163\n",
      "Rows Counter: 164\n",
      "Rows Counter: 165\n",
      "Rows Counter: 166\n",
      "Rows Counter: 167\n",
      "Rows Counter: 168\n",
      "Rows Counter: 169\n",
      "Rows Counter: 170\n",
      "Rows Counter: 171\n",
      "Rows Counter: 172\n",
      "Rows Counter: 173\n",
      "Rows Counter: 174\n",
      "Rows Counter: 175\n",
      "Rows Counter: 176\n",
      "Rows Counter: 177\n",
      "Rows Counter: 178\n",
      "Rows Counter: 179\n",
      "Rows Counter: 180\n",
      "Rows Counter: 181\n",
      "Rows Counter: 182\n",
      "Rows Counter: 183\n",
      "Rows Counter: 184\n",
      "Rows Counter: 185\n",
      "Rows Counter: 186\n",
      "Rows Counter: 187\n",
      "Rows Counter: 188\n",
      "Rows Counter: 189\n",
      "Rows Counter: 190\n",
      "Rows Counter: 191\n",
      "Rows Counter: 192\n",
      "Rows Counter: 193\n",
      "Rows Counter: 194\n",
      "Rows Counter: 195\n",
      "Rows Counter: 196\n",
      "Rows Counter: 197\n",
      "Rows Counter: 198\n",
      "Rows Counter: 199\n",
      "Rows Counter: 200\n",
      "Rows Counter: 201\n",
      "Rows Counter: 202\n",
      "Rows Counter: 203\n",
      "Rows Counter: 204\n",
      "Rows Counter: 205\n",
      "Rows Counter: 206\n",
      "Rows Counter: 207\n",
      "Rows Counter: 208\n",
      "Rows Counter: 209\n",
      "Rows Counter: 210\n",
      "Rows Counter: 211\n",
      "Rows Counter: 212\n",
      "Rows Counter: 213\n",
      "Rows Counter: 214\n",
      "Rows Counter: 215\n",
      "Rows Counter: 216\n",
      "Rows Counter: 217\n",
      "Rows Counter: 218\n",
      "Rows Counter: 219\n",
      "Rows Counter: 220\n",
      "Rows Counter: 221\n",
      "Rows Counter: 222\n",
      "Rows Counter: 223\n",
      "Rows Counter: 224\n",
      "Rows Counter: 225\n",
      "Rows Counter: 226\n",
      "Rows Counter: 227\n",
      "Rows Counter: 228\n",
      "Rows Counter: 229\n",
      "Rows Counter: 230\n",
      "Rows Counter: 231\n",
      "Rows Counter: 232\n",
      "Rows Counter: 233\n",
      "Rows Counter: 234\n",
      "Rows Counter: 235\n",
      "Rows Counter: 236\n",
      "Rows Counter: 237\n",
      "Rows Counter: 238\n",
      "Rows Counter: 239\n",
      "Rows Counter: 240\n",
      "Rows Counter: 241\n",
      "Rows Counter: 242\n",
      "Rows Counter: 243\n",
      "Rows Counter: 244\n",
      "Rows Counter: 245\n",
      "Rows Counter: 246\n",
      "Rows Counter: 247\n",
      "Rows Counter: 248\n",
      "Rows Counter: 249\n",
      "Rows Counter: 250\n",
      "Rows Counter: 251\n",
      "Rows Counter: 252\n",
      "Rows Counter: 253\n",
      "Rows Counter: 254\n",
      "Rows Counter: 255\n",
      "Rows Counter: 256\n",
      "Rows Counter: 257\n",
      "Rows Counter: 258\n",
      "Rows Counter: 259\n",
      "Rows Counter: 260\n",
      "Rows Counter: 261\n",
      "Rows Counter: 262\n",
      "Rows Counter: 263\n",
      "Rows Counter: 264\n",
      "Rows Counter: 265\n",
      "Rows Counter: 266\n",
      "Rows Counter: 267\n",
      "Rows Counter: 268\n",
      "Rows Counter: 269\n",
      "Rows Counter: 270\n",
      "Rows Counter: 271\n",
      "Rows Counter: 272\n",
      "Rows Counter: 273\n",
      "Rows Counter: 274\n",
      "Rows Counter: 275\n",
      "Rows Counter: 276\n",
      "Rows Counter: 277\n",
      "Rows Counter: 278\n",
      "Rows Counter: 279\n",
      "Rows Counter: 280\n",
      "Rows Counter: 281\n",
      "Rows Counter: 282\n",
      "Rows Counter: 283\n",
      "Rows Counter: 284\n",
      "Rows Counter: 285\n",
      "Rows Counter: 286\n",
      "Rows Counter: 287\n",
      "Rows Counter: 288\n",
      "Rows Counter: 289\n",
      "Rows Counter: 290\n",
      "Rows Counter: 291\n",
      "Rows Counter: 292\n",
      "Rows Counter: 293\n",
      "Rows Counter: 294\n",
      "Rows Counter: 295\n",
      "Rows Counter: 296\n",
      "Rows Counter: 297\n",
      "Rows Counter: 298\n",
      "Rows Counter: 299\n",
      "Rows Counter: 300\n",
      "Rows Counter: 301\n",
      "Rows Counter: 302\n",
      "Rows Counter: 303\n",
      "Rows Counter: 304\n",
      "Rows Counter: 305\n",
      "Rows Counter: 306\n",
      "Rows Counter: 307\n",
      "Rows Counter: 308\n",
      "Rows Counter: 309\n",
      "Rows Counter: 310\n",
      "Rows Counter: 311\n",
      "Rows Counter: 312\n",
      "Rows Counter: 313\n",
      "Rows Counter: 314\n",
      "Rows Counter: 315\n",
      "Rows Counter: 316\n",
      "Rows Counter: 317\n",
      "Rows Counter: 318\n",
      "Rows Counter: 319\n",
      "Rows Counter: 320\n",
      "Rows Counter: 321\n",
      "Rows Counter: 322\n",
      "Rows Counter: 323\n",
      "Rows Counter: 324\n",
      "Rows Counter: 325\n",
      "Rows Counter: 326\n",
      "Rows Counter: 327\n",
      "Rows Counter: 328\n",
      "Rows Counter: 329\n",
      "Rows Counter: 330\n",
      "Rows Counter: 331\n",
      "Rows Counter: 332\n",
      "Rows Counter: 333\n",
      "Rows Counter: 334\n",
      "Rows Counter: 335\n",
      "Rows Counter: 336\n",
      "Rows Counter: 337\n",
      "Rows Counter: 338\n",
      "Rows Counter: 339\n",
      "Rows Counter: 340\n",
      "Rows Counter: 341\n",
      "Rows Counter: 342\n",
      "Rows Counter: 343\n",
      "Rows Counter: 344\n",
      "Rows Counter: 345\n",
      "Rows Counter: 346\n",
      "Rows Counter: 347\n",
      "Rows Counter: 348\n",
      "Rows Counter: 349\n",
      "Rows Counter: 350\n",
      "Rows Counter: 351\n",
      "Rows Counter: 352\n",
      "Rows Counter: 353\n",
      "Rows Counter: 354\n",
      "Rows Counter: 355\n",
      "Rows Counter: 356\n",
      "Rows Counter: 357\n",
      "Rows Counter: 358\n",
      "Rows Counter: 359\n",
      "Rows Counter: 360\n"
     ]
    }
   ],
   "source": [
    "SentenceTransformer_model = SentenceTransformer(cos_model_name)\n",
    "df           = pd.DataFrame()\n",
    "newDF        = pd.DataFrame()\n",
    "df           = df_ORI\n",
    "#df.reset_index(inplace=True)\n",
    "cntr         = 1\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print('Rows Counter: ' + str(cntr))\n",
    "    text     = row[DATA_COLUMN]\n",
    "    all_text = df_AUG.iloc[index][DATA_COLUMN]\n",
    "    embd1 = create_embeddings(text=text, SentenceTransformer_model=SentenceTransformer_model)\n",
    "    embd2 = create_embeddings(text=all_text, SentenceTransformer_model=SentenceTransformer_model)\n",
    "    new_embd1 = ','.join(str(x) for x in embd1)\n",
    "    new_embd2 = ','.join(str(x) for x in embd2)\n",
    "    esim = euclidean_distance(embd1, embd2)\n",
    "    csim = cos_similarity(embd1, embd2)\n",
    "    jsim = jaccard_similarity(text, all_text)    \n",
    "    tmp = { \n",
    "        'text': [row[DATA_COLUMN]], \n",
    "        'label': [row[LABEL_COLUMN]], \n",
    "        'all_text': [all_text], \n",
    "        'original_embedding': [new_embd1], \n",
    "        'new_embedding': [new_embd2], \n",
    "        'ecu_similarity': [esim], \n",
    "        'cos_similarity': [csim], \n",
    "        'jacc_similarity': [jsim] \n",
    "    }\n",
    "    tmpDF = pd.DataFrame(tmp)\n",
    "#     print(tmpDF)\n",
    "    newDF = pd.concat([newDF, tmpDF], ignore_index=True)\n",
    "    \n",
    "    cntr = cntr + 1\n",
    "    #if cntr == 10:\n",
    "#     #    break;\n",
    "        \n",
    "#     # GPU Monitor\n",
    "#     if index%10 == 0:\n",
    "#         GPUs = GPU.getGPUs()  \n",
    "#         gpu = GPUs[0]    \n",
    "#         print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))        \n",
    "#         torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "396acd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03885619  0.01854845 -0.04066142 ...  0.01009195 -0.01660531\n",
      "  -0.00138946]\n",
      " [-0.00059496 -0.009242   -0.0587051  ...  0.01638779  0.01509569\n",
      "  -0.04368324]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb11756",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF['text_split'] = [list(x.split()) for x in newDF['text']]\n",
    "newDF['all_text_split'] = [x.split() for x in newDF['all_text']]\n",
    "# df['new_text_split'] = [str(x).split() for x in df['new_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c38163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Server\\miniconda3\\envs\\RALBERT\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "newDF[['bleu_sim_1','bleu_sim_2','bleu_sim_3','bleu_sim_4']] = [ calculate_bleu_scores ([[x]],[y]) for x, y in zip(newDF['text_split'], newDF['all_text_split'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7e3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>all_text</th>\n",
       "      <th>original_embedding</th>\n",
       "      <th>new_embedding</th>\n",
       "      <th>ecu_similarity</th>\n",
       "      <th>cos_similarity</th>\n",
       "      <th>jacc_similarity</th>\n",
       "      <th>text_split</th>\n",
       "      <th>all_text_split</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_2</th>\n",
       "      <th>bleu_sim_3</th>\n",
       "      <th>bleu_sim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lucu kak abbey cantik kayak orang haru</td>\n",
       "      <td>1</td>\n",
       "      <td>lucu kak abbey cantik kayak adiwarna orang haru</td>\n",
       "      <td>-0.008952065,0.04007555,0.009347842,-0.0112527...</td>\n",
       "      <td>-0.010526381,0.03891554,0.0057675247,-0.013351...</td>\n",
       "      <td>0.071316</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[lucu, kak, abbey, cantik, kayak, orang, haru]</td>\n",
       "      <td>[lucu, kak, abbey, cantik, kayak, adiwarna, or...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heran deh ngatain baperan wajar dese baper udi...</td>\n",
       "      <td>0</td>\n",
       "      <td>heran deh ngatain baperan wajar dese baper udi...</td>\n",
       "      <td>-0.0025755763,0.02613189,0.007338449,-0.015779...</td>\n",
       "      <td>-0.005544476,0.02702064,0.0063123675,-0.014782...</td>\n",
       "      <td>0.040416</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[heran, deh, ngatain, baperan, wajar, dese, ba...</td>\n",
       "      <td>[heran, deh, ngatain, baperan, wajar, dese, ba...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jujur ni org bagus kaga oplasada tu foto sblm ...</td>\n",
       "      <td>0</td>\n",
       "      <td>jujur ni org bagus kaga oplasada tu foto sblm ...</td>\n",
       "      <td>-0.03544854,-0.0025185551,0.0033979164,-0.0242...</td>\n",
       "      <td>-0.03311891,-0.0023508081,-0.006632578,-0.0260...</td>\n",
       "      <td>0.124963</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>[jujur, ni, org, bagus, kaga, oplasada, tu, fo...</td>\n",
       "      <td>[jujur, ni, org, bagus, kaga, oplasada, tu, fo...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haduuh orang gak akhlak bangeg kerja antem mul...</td>\n",
       "      <td>0</td>\n",
       "      <td>haduuh orang gak budi bahasa bangeg kerja ante...</td>\n",
       "      <td>0.00045949852,0.0074383696,0.011340753,-0.0033...</td>\n",
       "      <td>0.009412642,0.018586768,0.012307178,0.00205228...</td>\n",
       "      <td>0.270810</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>[haduuh, orang, gak, akhlak, bangeg, kerja, an...</td>\n",
       "      <td>[haduuh, orang, gak, budi, bahasa, bangeg, ker...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bingung jujur media rebut ngeliput orang kayak...</td>\n",
       "      <td>0</td>\n",
       "      <td>bingung jujur media jaring rebut ngeliput oran...</td>\n",
       "      <td>-0.030819902,0.036678318,-0.022147873,-0.02612...</td>\n",
       "      <td>-0.03201777,0.03360407,-0.026444586,-0.0279051...</td>\n",
       "      <td>0.056634</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[bingung, jujur, media, rebut, ngeliput, orang...</td>\n",
       "      <td>[bingung, jujur, media, jaring, rebut, ngelipu...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0             lucu kak abbey cantik kayak orang haru      1   \n",
       "1  heran deh ngatain baperan wajar dese baper udi...      0   \n",
       "2  jujur ni org bagus kaga oplasada tu foto sblm ...      0   \n",
       "3  haduuh orang gak akhlak bangeg kerja antem mul...      0   \n",
       "4  bingung jujur media rebut ngeliput orang kayak...      0   \n",
       "\n",
       "                                            all_text  \\\n",
       "0    lucu kak abbey cantik kayak adiwarna orang haru   \n",
       "1  heran deh ngatain baperan wajar dese baper udi...   \n",
       "2  jujur ni org bagus kaga oplasada tu foto sblm ...   \n",
       "3  haduuh orang gak budi bahasa bangeg kerja ante...   \n",
       "4  bingung jujur media jaring rebut ngeliput oran...   \n",
       "\n",
       "                                  original_embedding  \\\n",
       "0  -0.008952065,0.04007555,0.009347842,-0.0112527...   \n",
       "1  -0.0025755763,0.02613189,0.007338449,-0.015779...   \n",
       "2  -0.03544854,-0.0025185551,0.0033979164,-0.0242...   \n",
       "3  0.00045949852,0.0074383696,0.011340753,-0.0033...   \n",
       "4  -0.030819902,0.036678318,-0.022147873,-0.02612...   \n",
       "\n",
       "                                       new_embedding  ecu_similarity  \\\n",
       "0  -0.010526381,0.03891554,0.0057675247,-0.013351...        0.071316   \n",
       "1  -0.005544476,0.02702064,0.0063123675,-0.014782...        0.040416   \n",
       "2  -0.03311891,-0.0023508081,-0.006632578,-0.0260...        0.124963   \n",
       "3  0.009412642,0.018586768,0.012307178,0.00205228...        0.270810   \n",
       "4  -0.03201777,0.03360407,-0.026444586,-0.0279051...        0.056634   \n",
       "\n",
       "   cos_similarity  jacc_similarity  \\\n",
       "0           0.991         0.888889   \n",
       "1           0.997         1.000000   \n",
       "2           0.970         0.954545   \n",
       "3           0.822         0.944444   \n",
       "4           0.996         1.000000   \n",
       "\n",
       "                                          text_split  \\\n",
       "0     [lucu, kak, abbey, cantik, kayak, orang, haru]   \n",
       "1  [heran, deh, ngatain, baperan, wajar, dese, ba...   \n",
       "2  [jujur, ni, org, bagus, kaga, oplasada, tu, fo...   \n",
       "3  [haduuh, orang, gak, akhlak, bangeg, kerja, an...   \n",
       "4  [bingung, jujur, media, rebut, ngeliput, orang...   \n",
       "\n",
       "                                      all_text_split  bleu_sim_1  bleu_sim_2  \\\n",
       "0  [lucu, kak, abbey, cantik, kayak, adiwarna, or...        0.88        0.79   \n",
       "1  [heran, deh, ngatain, baperan, wajar, dese, ba...        1.00        0.94   \n",
       "2  [jujur, ni, org, bagus, kaga, oplasada, tu, fo...        0.94        0.90   \n",
       "3  [haduuh, orang, gak, budi, bahasa, bangeg, ker...        0.80        0.73   \n",
       "4  [bingung, jujur, media, jaring, rebut, ngelipu...        0.92        0.88   \n",
       "\n",
       "   bleu_sim_3  bleu_sim_4  \n",
       "0        0.68        0.59  \n",
       "1        0.90        0.86  \n",
       "2        0.86        0.84  \n",
       "3        0.65        0.53  \n",
       "4        0.82        0.76  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8396d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.to_csv(\"data/testing_distiluse-base-multilingual-cased.txt\", sep=\"\\t\", header=0,encoding='utf-16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118e2aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECU': 0.15499225413325277,\n",
       " 'COS': 0.9529583333333334,\n",
       " 'JAC': 0.953690701511386,\n",
       " 'BLEU': 0.9102500000000001}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIM_COFFICIENTS_THRESHOLDS = {'ECU': newDF[\"ecu_similarity\"].mean(), 'COS':newDF[\"cos_similarity\"].mean(), 'JAC':newDF[\"jacc_similarity\"].mean(), 'BLEU':newDF[\"bleu_sim_1\"].mean()}\n",
    "SIM_COFFICIENTS_THRESHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0116c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
