{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b11e6d1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a305f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bdf1d3",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_scores(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculates BLEU 1-4 scores based on NLTK functionality\n",
    "\n",
    "    Args:\n",
    "        references: List of reference sentences\n",
    "        hypotheses: List of generated sentences\n",
    "\n",
    "    Returns:\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4: BLEU scores\n",
    "\n",
    "    \"\"\"\n",
    "    #return len(references), len(hypotheses)\n",
    "    bleu_1 = np.round(corpus_bleu(references, hypotheses, weights=(1.0, 0., 0., 0.)), decimals=2)\n",
    "    bleu_2 = np.round(corpus_bleu(references, hypotheses, weights=(0.50, 0.50, 0., 0.)), decimals=2)\n",
    "    bleu_3 = np.round(corpus_bleu(references, hypotheses, weights=(0.34, 0.33, 0.33, 0.)), decimals=2)\n",
    "    bleu_4 = np.round(corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25)), decimals=2)\n",
    "    return bleu_1, bleu_2, bleu_3, bleu_4 \n",
    "\n",
    "# Functions\n",
    "def check_label (label):\n",
    "    for lbl in LABEL_TO_AUGMENT:\n",
    "        if lbl.upper() == label.upper():\n",
    "            return True\n",
    "    return False        \n",
    "\n",
    "def check_similarity_cofficient (given_value, label, current_sim_coff):\n",
    "#     if not check_label(label):\n",
    "#         return False\n",
    "#     else:\n",
    "    try:\n",
    "        v = float(given_value)\n",
    "        if float(SIM_COFFICIENTS_THRESHOLDS[current_sim_coff.upper()]) >= v:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        print('exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a3bf9",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9751ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetname = 'Cyberbullying_90_16_f_NO_RS'\n",
    "# datasetpath = \"datasets/xls/ArSarcasm-Unbalanced-Augmented-aragpt2-base.csv\"\n",
    "df = pd.read_csv( \"data/data_baru/data_training_90_16_f_NO_RS.txt\", sep=\"\\t\", encoding='utf-8')\n",
    "# df.columns = ['text', 'label', 'new_text', 'all_text', 'original_embbedding', 'new_embbedding', 'ecu_similarity', 'cos_similarity', 'jacc_similarity','text_split', 'all_text_split', 'new_text_split', 'bleu_sim_1','bleu_sim_2', 'bleu_sim_3', 'bleu_sim_4']\n",
    "df.columns = ['text', 'label', 'all_text', 'original_embbedding', 'new_embbedding', 'ecu_similarity', 'cos_similarity', 'jacc_similarity', 'bleu_sim_1']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d118bba",
   "metadata": {},
   "source": [
    "### Calculating Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text_split'] = [list(x.split()) for x in df['text']]\n",
    "# df['all_text_split'] = [x.split() for x in df['all_text']]\n",
    "# df['new_text_split'] = [str(x).split() for x in df['new_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdddcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df[['bleu_sim_1','bleu_sim_2','bleu_sim_3','bleu_sim_4']] = [ calculate_bleu_scores ([[x]],[y]) for x, y in zip(df['text_split'], df['all_text_split'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df[['bleu_sim_1','bleu_sim_1','bleu_sim_1','bleu_sim_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ecu_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cos_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ca37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"jacc_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bleu_sim_1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_datasets= []\n",
    "SIM_COFFICIENTS_THRESHOLDS = {'ECU': df[\"ecu_similarity\"].mean(), 'COS':df[\"cos_similarity\"].mean(), 'JAC':df[\"jacc_similarity\"].mean(), 'BLEU':df[\"bleu_sim_1\"].mean()}\n",
    "LABEL_TO_AUGMENT = ['positive', 'negative']\n",
    "DATA_COLUMN = \"text\"\n",
    "LABEL_COLUMN = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bdb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_COFFICIENTS_THRESHOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906b879",
   "metadata": {},
   "source": [
    "### Augmentation (All-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('All text augmentation is started... ')\n",
    "for index, row in df.iterrows():\n",
    "    tmpDF = pd.DataFrame({'text': [row[DATA_COLUMN]], 'label': [row[LABEL_COLUMN]]})\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "\n",
    "    EcuDF = pd.concat([EcuDF, tmpDF], ignore_index=True)\n",
    "    CosDF = pd.concat([CosDF, tmpDF], ignore_index=True)\n",
    "    JacDF = pd.concat([JacDF, tmpDF], ignore_index=True)\n",
    "    BleDF = pd.concat([BleDF, tmpDF], ignore_index=True)\n",
    "\n",
    "    tmpDF = pd.DataFrame({'text': [row['all_text']], 'label': [row[LABEL_COLUMN]]})\n",
    "    # Check similarity\n",
    "    if check_similarity_cofficient(Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = pd.concat([EcuDF, tmpDF], ignore_index=True)\n",
    "\n",
    "    if check_similarity_cofficient(Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = pd.concat([CosDF, tmpDF], ignore_index=True)\n",
    "\n",
    "    if check_similarity_cofficient(Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = pd.concat([JacDF, tmpDF], ignore_index=True)\n",
    "\n",
    "    if check_similarity_cofficient(Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = pd.concat([BleDF, tmpDF], ignore_index=True)\n",
    "\n",
    "print('All text augmentation is finished ... ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d12cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "EcuDF.to_excel( \"data/data_baru/Augmented-Dataset/All/\"+datasetname+\"-Augmented-ECU-ALL-Text-Final.xlsx\", index=False)\n",
    "CosDF.to_excel( \"data/data_baru/Augmented-Dataset/All/\"+datasetname+\"-Augmented-COS-ALL-Text-Final.xlsx\", index=False)\n",
    "JacDF.to_excel( \"data/data_baru/Augmented-Dataset/All/\"+datasetname+\"-Augmented-JAC-ALL-Text-Final.xlsx\", index=False)\n",
    "BleDF.to_excel( \"data/data_baru/Augmented-Dataset/All/\"+datasetname+\"-Augmented-BLE-ALL-Text-Final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel( \"data/data_baru/Augmented-Dataset/xls/ArSarcasm-Unbalanced-aragpt2-base.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfee97e",
   "metadata": {},
   "source": [
    "### Augmentation (New-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a9fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('new text augmentation is started... ')\n",
    "for index, row in df.iterrows():         \n",
    "    tmpDF = { 'text': row[DATA_COLUMN], 'label': row[LABEL_COLUMN]}\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "    \n",
    "    EcuDF = pd.concat([EcuDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    CosDF = pd.concat([CosDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    JacDF = pd.concat([JacDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    BleDF = pd.concat([BleDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    tmpDF = { 'text': row['all_text'], 'label': row[LABEL_COLUMN]}\n",
    "    # Check similarity \n",
    "    if check_similarity_cofficient (Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = pd.concat([EcuDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    if check_similarity_cofficient (Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = pd.concat([CosDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    if check_similarity_cofficient (Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = pd.concat([JacDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    if check_similarity_cofficient (Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = pd.concat([BleDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "        \n",
    "print('new text augmentation is finished ... ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d220ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "EcuDF.to_excel( \"data/data_baru/Augmented-Dataset/New/\"+datasetname+\"-Augmented-ECU-New-Text-Final.xlsx\", index=False)\n",
    "CosDF.to_excel( \"data/data_baru/Augmented-Dataset/New/\"+datasetname+\"-Augmented-COS-New-Text-Final.xlsx\", index=False)\n",
    "JacDF.to_excel( \"data/data_baru/Augmented-Dataset/New/\"+datasetname+\"-Augmented-JAC-New-Text-Final.xlsx\", index=False)\n",
    "BleDF.to_excel( \"data/data_baru/Augmented-Dataset/New/\"+datasetname+\"-Augmented-BLE-New-Text-Final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de3478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
